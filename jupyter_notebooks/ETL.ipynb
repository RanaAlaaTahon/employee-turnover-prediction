{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cbcca5",
   "metadata": {},
   "source": [
    "# **ETL (Extract, Transform, Load)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c7f3e",
   "metadata": {},
   "source": [
    "The [IBM HR Analytics Employee Attrition & Performance dataset](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)  is a fictional dataset created by IBM data scientists to simulate real-world HR data. It contains information about employeesâ€™ demographics, job roles, satisfaction levels, performance, and employment history. The dataset has 1,470 rows (employees) and 35 columns, including both categorical and numerical variables, and is used to explore the factors that influence employee attrition and performance. The main feature categories are:\n",
    "\n",
    "- **Demographics:** Age, Gender, MaritalStatus, Education, EducationField\n",
    "\n",
    "- **Job Details:** Department, JobRole, JobLevel, JobInvolvement, YearsAtCompany, YearsInCurrentRole, YearsWithCurrManager\n",
    "\n",
    "- **Compensation:** MonthlyIncome, MonthlyRate, DailyRate, HourlyRate, PercentSalaryHike, StockOptionLevel\n",
    "\n",
    "- **Satisfaction Metrics:** JobSatisfaction, EnvironmentSatisfaction, RelationshipSatisfaction, WorkLifeBalance\n",
    "\n",
    "- **Performance & Experience:** PerformanceRating, TotalWorkingYears, NumCompaniesWorked, TrainingTimesLastYear, YearsSinceLastPromotion\n",
    "\n",
    "- **Other Attributes:** DistanceFromHome, BusinessTravel, OverTime, StandardHours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a837c",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The objective of this notebook is to perform the ETL (Extract, Transform, Load) process for the [IBM HR Analytics Employee Attrition & Performance dataset](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset). It extracts raw HR data, cleans missing or mismatched values, standardizes categorical encodings, and prepares numerical variables. The transformed dataset is then structured for exploratory data analysis and predictive modeling to uncover key factors influencing employee attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b8a4e",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "The dataset was obtained from [Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabf44c",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "The cleaned csv file found [here]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce1b9c",
   "metadata": {},
   "source": [
    "# ETL Process\n",
    "\n",
    "- Load the dataset\n",
    "- Understand dataset structure and content\n",
    "- Convert data types\n",
    "- Clean the dataset\n",
    "-  \n",
    "- \n",
    "- Save the clean dataset as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec6942",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b736d0b",
   "metadata": {},
   "source": [
    "# Change working directory\n",
    "Change the working directory from its current folder to its parent folder as the notebooks will be stored in a subfolder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903fba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amron\\\\Desktop\\\\employee-turnover-prediction\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9bf9c",
   "metadata": {},
   "source": [
    "Make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea61730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4884f2a",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ef2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amron\\\\Desktop\\\\employee-turnover-prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f3d91",
   "metadata": {},
   "source": [
    "Changing path directory to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828aaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path directory\n",
    "raw_data_dir = os.path.join(current_dir, 'data_set/raw') \n",
    "\n",
    "#path directory\n",
    "processed_data_dir = os.path.join(current_dir, 'data_set/processed') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279e71a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff43f2",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c19a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #import numpy\n",
    "import pandas as pd #import pandas\n",
    "import matplotlib.pyplot as plt #import matplotlib\n",
    "import seaborn as sns #import seaborn\n",
    "import plotly.express as px # import plotly\n",
    "sns.set_style('whitegrid') #set style for visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc6fac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df384e8c",
   "metadata": {},
   "source": [
    "# Load the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d94433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a4283",
   "metadata": {},
   "source": [
    "The raw dataset is loaded using Pandas for ETL process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41067d23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf6ff0",
   "metadata": {},
   "source": [
    "# Understand the dataset structure and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2349380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8055d",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8d3ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6f1f9",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729ecdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eb2ba",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935c17a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8f7c8",
   "metadata": {},
   "source": [
    "# Store and load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5679be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5392e",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37799949",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d99fe",
   "metadata": {},
   "source": [
    "# Cleaned Dataset Summary & Insights\n",
    "\n",
    "- \n",
    "- \n",
    "- \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
